# ðŸ§  BRAIN Project

**B**ridging **R**easoning and **A**I with **I**ntelligent **N**euro-symbolic Systems

Un solveur neuro-symbolique pour les puzzles [ARC-AGI](https://arcprize.org/) (Abstraction and Reasoning Corpus).

---

## ðŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [Format des donnÃ©es](#format-des-donnÃ©es)
- [Exemples](#exemples)

---

## Description

BRAIN combine :
- **Perception symbolique** : DÃ©tection automatique de formes gÃ©omÃ©triques (carrÃ©s, rectangles, lignes, formes en L/T/+, etc.)
- **DÃ©tection de transformations** : Identification automatique des rÃ¨gles (translation, rotation, rÃ©flexion, changement de couleur)
- **Raisonnement LLM** : Utilisation d'un modÃ¨le de langage local (Ollama) pour infÃ©rer les rÃ¨gles
- **ExÃ©cution symbolique** : Application des transformations sur les grilles

### Pipeline

```
Input Grid â†’ Perception â†’ Transformation Detection â†’ Prompting â†’ LLM â†’ Execution â†’ Analysis â†’ Visualization
```

---

## PrÃ©requis

### 1. Python 3.10+

VÃ©rifiez votre version :
```bash
python3 --version
```

### 2. Ollama (LLM local)

Installez Ollama depuis [ollama.ai](https://ollama.ai/) :

**macOS :**
```bash
brew install ollama
```

**Linux :**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows :**
TÃ©lÃ©chargez depuis [ollama.ai/download](https://ollama.ai/download)

### 3. TÃ©lÃ©charger un modÃ¨le LLM

Lancez Ollama et tÃ©lÃ©chargez le modÃ¨le `llama3` :
```bash
# DÃ©marrer le service Ollama (si pas dÃ©jÃ  lancÃ©)
ollama serve &

# TÃ©lÃ©charger le modÃ¨le (environ 4.7 GB)
ollama pull llama3
```

---

## Installation

### 1. Cloner/accÃ©der au projet

```bash
cd chemin/vers/BRAIN_PROJECT
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv venv
```

### 3. Activer l'environnement

**macOS/Linux :**
```bash
source venv/bin/activate
```

**Windows :**
```bash
venv\Scripts\activate
```

### 4. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## Utilisation

### Commande de base

```bash
python main.py --task data/mock_task.json
```

### Options disponibles

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--task FICHIER` | Chemin vers le fichier JSON de la tÃ¢che | - |
| `--model MODELE` | Nom du modÃ¨le Ollama | `llama3` |
| `--no-viz` | DÃ©sactiver la visualisation graphique | `False` |
| `--quiet` | Mode silencieux (moins de logs) | `False` |
| `--demo` | ExÃ©cuter une dÃ©mo avec donnÃ©es d'exemple | - |

### Exemples de commandes

```bash
# RÃ©soudre une tÃ¢che avec visualisation
python main.py --task data/mock_task.json

# Sans visualisation (plus rapide)
python main.py --task data/mock_task.json --no-viz

# Avec un autre modÃ¨le
python main.py --task data/mock_task.json --model llama3.2

# Mode silencieux
python main.py --task data/mock_task.json --quiet --no-viz
```

### Utilisation avec l'environnement virtuel (sans l'activer)

```bash
./venv/bin/python main.py --task data/mock_task.json --no-viz
```

---

## Structure du projet

```
BRAIN_PROJECT/
â”‚
â”œâ”€â”€ data/                       # DonnÃ©es d'entrÃ©e (puzzles ARC)
â”‚   â””â”€â”€ mock_task.json          # Exemple de tÃ¢che
â”‚
â”œâ”€â”€ modules/                    # Modules du pipeline
â”‚   â”œâ”€â”€ __init__.py             # Exports
â”‚   â”œâ”€â”€ types.py                # Classes de donnÃ©es (Grid, ARCTask)
â”‚   â”œâ”€â”€ detector.py             # DÃ©tection de formes
â”‚   â”œâ”€â”€ transformation_detector.py  # DÃ©tection de transformations
â”‚   â”œâ”€â”€ prompt_maker.py         # GÃ©nÃ©ration de prompts
â”‚   â”œâ”€â”€ llm_client.py           # Communication avec Ollama
â”‚   â”œâ”€â”€ executor.py             # ExÃ©cution des actions
â”‚   â”œâ”€â”€ analyzer.py             # Analyse des rÃ©sultats
â”‚   â””â”€â”€ visualizer.py           # Visualisation matplotlib
â”‚
â”œâ”€â”€ main.py                     # Point d'entrÃ©e principal
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ CAPABILITIES.md             # Documentation des capacitÃ©s
â””â”€â”€ README.md                   # Ce fichier
```

---

## Format des donnÃ©es

Les fichiers de tÃ¢ches suivent le format officiel ARC-AGI :

```json
{
  "train": [
    {
      "input": [[0, 0, 2], [0, 2, 2], [0, 0, 0]],
      "output": [[0, 0, 0], [0, 0, 2], [0, 2, 2]]
    }
  ],
  "test": [
    {
      "input": [[2, 2, 0], [2, 0, 0], [0, 0, 0]],
      "output": [[0, 0, 0], [2, 2, 0], [2, 0, 0]]
    }
  ]
}
```

### Palette de couleurs ARC

| Code | Couleur |
|------|---------|
| 0 | Noir (fond) |
| 1 | Bleu |
| 2 | Rouge |
| 3 | Vert |
| 4 | Jaune |
| 5 | Gris |
| 6 | Magenta |
| 7 | Orange |
| 8 | Cyan |
| 9 | Marron |

---

## Exemples

### Exemple 1 : Translation simple

La tÃ¢che `mock_task.json` incluse dÃ©place un carrÃ© rouge de 3 pixels vers la droite.

```bash
python main.py --task data/mock_task.json --no-viz
```

**Sortie attendue :**
```
STEP 1b: TRANSFORMATION DETECTION
  Example 1: [100%] Translation: dx=3 (right), dy=0 (down)
  Example 2: [100%] Translation: dx=3 (right), dy=0 (down)

STEP 5: ANALYSIS (Evaluation)
  âœ“ Correct: True
  ðŸ“Š Accuracy: 100.00%
```

### Exemple 2 : Utiliser vos propres puzzles

1. CrÃ©ez un fichier JSON dans `data/` suivant le format ARC
2. ExÃ©cutez :
```bash
python main.py --task data/votre_puzzle.json
```

---

## DÃ©pannage

### Erreur : "Ollama not installed"

```bash
pip install ollama
```

### Erreur : "Connection refused" 

Ollama n'est pas lancÃ© :
```bash
ollama serve
```

### Erreur : "Model not found"

TÃ©lÃ©chargez le modÃ¨le :
```bash
ollama pull llama3
```

### Visualisation bloquÃ©e / crash matplotlib

Utilisez l'option `--no-viz` :
```bash
python main.py --task data/mock_task.json --no-viz
```

---

## Documentation

Consultez `CAPABILITIES.md` pour la liste complÃ¨te des fonctionnalitÃ©s :
- Formes dÃ©tectÃ©es
- Transformations supportÃ©es
- Actions disponibles
- MÃ©triques d'Ã©valuation

---

## Auteurs

Projet BRAIN - ISAE-SUPAERO
