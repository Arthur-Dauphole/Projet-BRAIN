# ğŸ§  BRAIN Project

**B**ridging **R**easoning and **A**I with **I**ntelligent **N**euro-symbolic Systems

Un solveur neuro-symbolique pour les puzzles [ARC-AGI](https://arcprize.org/) (Abstraction and Reasoning Corpus).

> **Version:** 2.3.0  
> **DerniÃ¨re mise Ã  jour:** Janvier 2026

---

## ğŸ“‹ Table des matiÃ¨res

- [Description](#description)
- [PrÃ©requis](#prÃ©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Ã‰valuation batch](#Ã©valuation-batch)
- [Comparaison de modÃ¨les](#comparaison-de-modÃ¨les)
- [Structure du projet](#structure-du-projet)
- [Format des donnÃ©es](#format-des-donnÃ©es)
- [Exemples](#exemples)

---

## Description

BRAIN combine :
- **Perception symbolique** : DÃ©tection automatique de formes gÃ©omÃ©triques (carrÃ©s, rectangles, lignes, formes en L/T/+, blobs)
- **DÃ©tection de transformations** : Identification automatique des rÃ¨gles (translation, rotation, rÃ©flexion, changement de couleur, tiling, etc.)
- **Raisonnement LLM** : Utilisation d'un modÃ¨le de langage local (Ollama) pour infÃ©rer les rÃ¨gles
- **ExÃ©cution symbolique** : Application des transformations sur les grilles
- **Ã‰valuation batch** : ExÃ©cution et analyse de multiples tÃ¢ches
- **Comparaison de modÃ¨les** : Benchmark de diffÃ©rents LLMs sur les mÃªmes tÃ¢ches

### Pipeline

```
Input Grid â†’ Perception â†’ Transformation Detection â†’ Prompting â†’ LLM â†’ Execution â†’ Analysis â†’ Visualization
```

---

## PrÃ©requis

### 1. Python 3.10+

VÃ©rifiez votre version :
```bash
python3 --version
```

### 2. Ollama (LLM local)

Installez Ollama depuis [ollama.ai](https://ollama.ai/) :

**macOS :**
```bash
brew install ollama
```

**Linux :**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows :**
TÃ©lÃ©chargez depuis [ollama.ai/download](https://ollama.ai/download)

### 3. TÃ©lÃ©charger un modÃ¨le LLM

Lancez Ollama et tÃ©lÃ©chargez le modÃ¨le `llama3` :
```bash
# DÃ©marrer le service Ollama (si pas dÃ©jÃ  lancÃ©)
ollama serve &

# TÃ©lÃ©charger le modÃ¨le (environ 4.7 GB)
ollama pull llama3
```

---

## Installation

### 1. Cloner/accÃ©der au projet

```bash
cd chemin/vers/BRAIN_PROJECT
```

### 2. CrÃ©er un environnement virtuel

```bash
python3 -m venv venv
```

### 3. Activer l'environnement

**macOS/Linux :**
```bash
source venv/bin/activate
```

**Windows :**
```bash
venv\Scripts\activate
```

### 4. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

---

## Utilisation

### Commande de base

```bash
python main.py --task data/mock_task.json
```

### Options disponibles

| Option | Description | DÃ©faut |
|--------|-------------|--------|
| `--task FICHIER` | Chemin vers le fichier JSON de la tÃ¢che | - |
| `--batch DIR` | Lancer un batch sur toutes les tÃ¢ches d'un rÃ©pertoire | - |
| `--model MODELE` | Nom du modÃ¨le Ollama | `llama3` |
| `--limit N` | Limiter le nombre de tÃ¢ches (batch) | Toutes |
| `--no-viz` | DÃ©sactiver la visualisation graphique | `False` |
| `--quiet` | Mode silencieux (moins de logs) | `False` |
| `--self-correct` | Activer la boucle d'auto-correction | `False` |
| `--demo` | ExÃ©cuter une dÃ©mo avec donnÃ©es d'exemple | - |

### Exemples de commandes

```bash
# RÃ©soudre une tÃ¢che avec visualisation
python main.py --task data/mock_task.json

# Sans visualisation (plus rapide)
python main.py --task data/mock_task.json --no-viz

# Avec un autre modÃ¨le
python main.py --task data/mock_task.json --model mistral

# Mode silencieux
python main.py --task data/mock_task.json --quiet --no-viz

# Avec auto-correction (retry si erreur)
python main.py --task data/mock_task.json --self-correct
```

---

## Ã‰valuation batch

ExÃ©cutez plusieurs tÃ¢ches et collectez des statistiques :

```bash
# Toutes les tÃ¢ches du dossier data/
python main.py --batch data/

# LimitÃ© Ã  10 tÃ¢ches
python main.py --batch data/ --limit 10

# Avec un modÃ¨le spÃ©cifique
python main.py --batch data/ --model mistral

# RÃ©sultats dans un dossier personnalisÃ©
python main.py --batch data/ --output results_mistral/
```

**RÃ©sultats gÃ©nÃ©rÃ©s :**
- `summary.json` - Statistiques agrÃ©gÃ©es
- `tasks.csv` - RÃ©sultats par tÃ¢che
- `images/` - Visualisations de chaque tÃ¢che

---

## Comparaison de modÃ¨les

Comparez les performances de plusieurs LLMs :

```bash
# Lister les modÃ¨les recommandÃ©s
python compare_models.py --list-models

# Comparer llama3 et mistral sur 10 tÃ¢ches
python compare_models.py --models llama3 mistral --limit 10

# Avec gÃ©nÃ©ration de graphiques
python compare_models.py --models llama3 mistral --visualize

# GÃ©nÃ©rer les graphiques depuis des rÃ©sultats existants
python compare_models.py --viz-only comparison_results/
```

**Important :** `compare_models.py` utilise exactement le mÃªme pipeline que `main.py --batch`, garantissant des rÃ©sultats 100% cohÃ©rents.

### ModÃ¨les recommandÃ©s

| ModÃ¨le | Description | Taille | Installation |
|--------|-------------|--------|--------------|
| `llama3` | Meta Llama 3 8B - Bon gÃ©nÃ©raliste | 4.7 GB | `ollama pull llama3` |
| `mistral` | Mistral 7B - Excellent raisonnement | 4.1 GB | `ollama pull mistral` |
| `phi3` | Microsoft Phi-3 - Petit mais capable | 2.2 GB | `ollama pull phi3` |

### Visualisations gÃ©nÃ©rÃ©es

- `accuracy_comparison.png` - Barplot accuracy par modÃ¨le
- `time_comparison.png` - Temps de rÃ©ponse moyen
- `accuracy_vs_time.png` - Trade-off accuracy/temps
- `summary_dashboard.png` - Dashboard complet

---

## Structure du projet

```
BRAIN_PROJECT/
â”‚
â”œâ”€â”€ ğŸ“‚ data/                              # 53 puzzles ARC au format JSON
â”‚   â”œâ”€â”€ task_translation_*.json           # 8 tÃ¢ches de translation
â”‚   â”œâ”€â”€ task_rotation_*.json              # 7 tÃ¢ches de rotation
â”‚   â”œâ”€â”€ task_reflection_*.json            # 6 tÃ¢ches de rÃ©flexion
â”‚   â”œâ”€â”€ task_color_change_*.json          # 6 tÃ¢ches de changement de couleur
â”‚   â”œâ”€â”€ task_draw_line_*.json             # 5 tÃ¢ches de tracÃ© de ligne
â”‚   â”œâ”€â”€ task_add_border_*.json            # 4 tÃ¢ches d'ajout de contour
â”‚   â”œâ”€â”€ task_tiling_*.json                # 3 tÃ¢ches de pavage
â”‚   â”œâ”€â”€ task_composite_*.json             # 3 tÃ¢ches de transformations composÃ©es
â”‚   â”œâ”€â”€ task_blob_*.json                  # 4 tÃ¢ches sur formes irrÃ©guliÃ¨res
â”‚   â””â”€â”€ task_multi_objects*.json          # 2 tÃ¢ches multi-objets
â”‚
â”œâ”€â”€ ğŸ“‚ modules/                           # Pipeline principal (12 modules)
â”‚   â”œâ”€â”€ __init__.py                       # Exports publics
â”‚   â”œâ”€â”€ types.py                          # Structures de donnÃ©es (Grid, ARCTask)
â”‚   â”œâ”€â”€ detector.py                       # Perception : dÃ©tection de formes
â”‚   â”œâ”€â”€ transformation_detector.py        # Analyse : dÃ©tection de transformations
â”‚   â”œâ”€â”€ prompt_maker.py                   # GÃ©nÃ©ration de prompts LLM
â”‚   â”œâ”€â”€ llm_client.py                     # Communication Ollama (parsing JSON)
â”‚   â”œâ”€â”€ executor.py                       # ExÃ©cution des actions DSL
â”‚   â”œâ”€â”€ analyzer.py                       # Ã‰valuation des rÃ©sultats
â”‚   â”œâ”€â”€ visualizer.py                     # Visualisation matplotlib
â”‚   â”œâ”€â”€ batch_runner.py                   # Ã‰valuation batch de tÃ¢ches
â”‚   â”œâ”€â”€ model_comparator.py               # Comparaison de modÃ¨les + graphiques
â”‚   â”œâ”€â”€ logger.py                         # Logging structurÃ© (TIER 1)
â”‚   â””â”€â”€ rule_memory.py                    # MÃ©moire RAG de rÃ¨gles (TIER 3)
â”‚
â”œâ”€â”€ ğŸ“‚ data_analysis/                     # Outils d'analyse scientifique
â”‚   â”œâ”€â”€ __init__.py                       # Exports
â”‚   â”œâ”€â”€ data_loader.py                    # Chargement rÃ©sultats batch
â”‚   â”œâ”€â”€ metrics.py                        # Calcul de mÃ©triques statistiques
â”‚   â”œâ”€â”€ visualizer.py                     # Graphiques IEEE/LaTeX
â”‚   â””â”€â”€ report_generator.py               # GÃ©nÃ©ration rapports (Markdown, LaTeX)
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                         # Jupyter notebooks
â”‚   â””â”€â”€ analysis_example.ipynb            # Exemple d'analyse de donnÃ©es
â”‚
â”œâ”€â”€ ğŸ“‚ results/                           # [GÃ©nÃ©rÃ©] RÃ©sultats single/batch
â”œâ”€â”€ ğŸ“‚ comparison_results/                # [GÃ©nÃ©rÃ©] RÃ©sultats comparaison modÃ¨les
â”œâ”€â”€ ğŸ“‚ analysis/                          # [GÃ©nÃ©rÃ©] Figures et rapports
â”‚
â”œâ”€â”€ ğŸ main.py                            # Point d'entrÃ©e (single + batch)
â”œâ”€â”€ ğŸ compare_models.py                  # CLI comparaison de modÃ¨les
â”œâ”€â”€ ğŸ analyze.py                         # CLI analyse de donnÃ©es
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt                   # DÃ©pendances Python
â”œâ”€â”€ ğŸ“‹ CAPABILITIES.md                    # Documentation technique dÃ©taillÃ©e
â””â”€â”€ ğŸ“‹ README.md                          # Ce fichier
```

### Description des modules principaux

| Module | RÃ´le |
|--------|------|
| `detector.py` | Identifie les formes (carrÃ©s, rectangles, L, T, blobs...) |
| `transformation_detector.py` | DÃ©tecte les rÃ¨gles entre input/output |
| `executor.py` | Applique les transformations (translate, rotate, etc.) |
| `batch_runner.py` | ExÃ©cute et agrÃ¨ge plusieurs tÃ¢ches |
| `model_comparator.py` | Compare les performances de plusieurs LLMs |

---

## Format des donnÃ©es

Les fichiers de tÃ¢ches suivent le format officiel ARC-AGI :

```json
{
  "train": [
    {
      "input": [[0, 0, 2], [0, 2, 2], [0, 0, 0]],
      "output": [[0, 0, 0], [0, 0, 2], [0, 2, 2]]
    }
  ],
  "test": [
    {
      "input": [[2, 2, 0], [2, 0, 0], [0, 0, 0]],
      "output": [[0, 0, 0], [2, 2, 0], [2, 0, 0]]
    }
  ]
}
```

### Palette de couleurs ARC

| Code | Couleur |
|------|---------|
| 0 | Noir (fond) |
| 1 | Bleu |
| 2 | Rouge |
| 3 | Vert |
| 4 | Jaune |
| 5 | Gris |
| 6 | Magenta |
| 7 | Orange |
| 8 | Cyan |
| 9 | Marron |

---

## Exemples

### Exemple 1 : Translation simple

La tÃ¢che `mock_task.json` incluse dÃ©place un carrÃ© rouge de 3 pixels vers la droite.

```bash
python main.py --task data/mock_task.json --no-viz
```

**Sortie attendue :**
```
STEP 1b: TRANSFORMATION DETECTION
  Example 1: [100%] Translation: dx=3 (right), dy=0 (down)
  Example 2: [100%] Translation: dx=3 (right), dy=0 (down)

STEP 5: ANALYSIS (Evaluation)
  âœ“ Correct: True
  ğŸ“Š Accuracy: 100.00%
```

### Exemple 2 : Utiliser vos propres puzzles

1. CrÃ©ez un fichier JSON dans `data/` suivant le format ARC
2. ExÃ©cutez :
```bash
python main.py --task data/votre_puzzle.json
```

---

## DÃ©pannage

### Erreur : "Ollama not installed"

```bash
pip install ollama
```

### Erreur : "Connection refused" 

Ollama n'est pas lancÃ© :
```bash
ollama serve
```

### Erreur : "Model not found"

TÃ©lÃ©chargez le modÃ¨le :
```bash
ollama pull llama3
```

### Visualisation bloquÃ©e / crash matplotlib

Utilisez l'option `--no-viz` :
```bash
python main.py --task data/mock_task.json --no-viz
```

---

## Documentation

Consultez `CAPABILITIES.md` pour la liste complÃ¨te des fonctionnalitÃ©s :
- Formes dÃ©tectÃ©es
- Transformations supportÃ©es
- Actions disponibles
- MÃ©triques d'Ã©valuation

---

## Auteurs

Projet BRAIN - ISAE-SUPAERO
